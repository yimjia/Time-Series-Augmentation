{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder (CVAE) <br> For Time Series Augmentaion\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input the user-defined parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directory (change the directory to the folder including your time series data)\n",
    "file_dir = 'C:/Users/jiayi/Desktop/CVAE Codes for GitHub/'\n",
    "\n",
    "\n",
    "# Latent space size (usually it is a small number e.g., <= 8)\n",
    "latent_dim = 4\n",
    "\n",
    "\n",
    "# Number of epochs\n",
    "NUM_EPOCH = 50000\n",
    "\n",
    "\n",
    "# Stop training when loss reaching\n",
    "Loss_Stop = 0.0000\n",
    "\n",
    "\n",
    "# Initial learning rate for Adam optimizer\n",
    "Learning_Rate = 0.005\n",
    "\n",
    "\n",
    "# Initial learning rate step decay parameters\n",
    "Drop_Rate1 = 0.80\n",
    "NUM_EPOCH_DROP1 = 5000\n",
    "\n",
    "Drop_Rate2 = 0.90\n",
    "NUM_EPOCH_DROP2 = 10000\n",
    "\n",
    "Drop_Rate3 = 0.95\n",
    "NUM_EPOCH_DROP3 = 20000\n",
    "\n",
    "Drop_Rate4 = 1.00\n",
    "\n",
    "\n",
    "# Drop learning rate every Drop_Epoch\n",
    "Drop_Epoch = 500\n",
    "\n",
    "\n",
    "# Define a GPU usage\n",
    "# CPU = -1, GPU0 = 0, GPU1 = 1\n",
    "GPU_ID = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is specified\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_ID) \n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for model, data, and figure\n",
    "import shutil\n",
    "\n",
    "# Folder name\n",
    "ID = f\"_Lat{latent_dim}_Epoch{NUM_EPOCH}\" \n",
    "\n",
    "# Model\n",
    "model_dir = f\"Model{str(ID)}\" \n",
    "modelExist = os.path.exists(model_dir)\n",
    "if modelExist:\n",
    "    shutil.rmtree(model_dir)\n",
    "    os.makedirs(model_dir) \n",
    "    print('Model folder exists, delete the current files in this folder.')\n",
    "else:\n",
    "    os.makedirs(model_dir)    \n",
    "    print('Model folder does not exist, create this folder.')\n",
    "    \n",
    "# Data\n",
    "data_dir = f\"Data{str(ID)}\" \n",
    "dataExist = os.path.exists(data_dir)\n",
    "if dataExist:\n",
    "    shutil.rmtree(data_dir)\n",
    "    os.makedirs(data_dir) \n",
    "    print('Data folder exists, delete the current files in this folder.')\n",
    "else:\n",
    "    os.makedirs(data_dir)    \n",
    "    print('Data folder does not exist, create this folder.')\n",
    "        \n",
    "# Figure\n",
    "figure_dir = f\"Figure{str(ID)}\" \n",
    "figureExist = os.path.exists(figure_dir)\n",
    "if figureExist:\n",
    "    shutil.rmtree(figure_dir)    \n",
    "    os.makedirs(figure_dir) \n",
    "    print('Figure folder exists, delete the current files in this folder.')\n",
    "else:\n",
    "    os.makedirs(figure_dir)    \n",
    "    print('Figure folder does not exist, create this folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Conv2DTranspose, Lambda, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import time\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import PReLU\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time series data\n",
    "Data = scipy.io.loadmat(file_dir + 'TimeSeries.mat')\n",
    "# Notes: \n",
    "# 'TimeSeries.mat' is a Nt*1 vector of cells (Nt is the number of time series).\n",
    "# Each cell includes a Ns*D matrix (Ni is the number of time steps, D is the number of dimensions).\n",
    "\n",
    "T_Raw = Data[\"TimeSeries\"]     \n",
    "\n",
    "# Reshape the time series data\n",
    "T_Raw = np.squeeze(T_Raw)\n",
    "T = np.empty((T_Raw.shape[0], T_Raw[0].shape[0], T_Raw[0].shape[1]))\n",
    "for i in range(T_Raw.shape[0]):\n",
    "    T[i] = T_Raw[i]\n",
    "\n",
    "T = T.reshape(-1, T.shape[1],T.shape[2], 1)\n",
    "\n",
    "print('')\n",
    "print('Time series data shape = ', T.shape)\n",
    "print('')\n",
    "print('Number of time series =', T.shape[0])\n",
    "print('Number of time steps in each time series =', T.shape[1])\n",
    "print('Number of dimensions in each time series = ', T.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Encoder\n",
    "### Note: The activation function, number of filters, kernel size, pooling size, strides, padding, and number of nodes in dense layers can be defined based on user's preference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_encoder = Input(shape=(T.shape[1],T.shape[2],T.shape[3]), name = 'x_T')\n",
    "\n",
    "\n",
    "# Activation function\n",
    "act_fun = LeakyReLU(alpha=0.5)\n",
    "# act_fun = 'tanh'\n",
    "# act_fun = 'ReLU'\n",
    "# act_fun = 'PReLU'\n",
    "\n",
    "\n",
    "# Convolutional and max pooling layers\n",
    "x_C1 = Conv2D(filters = 16, kernel_size = (3,3), padding=\"same\",\n",
    "              activation=act_fun, name = 'x_C1',\n",
    "              kernel_initializer=initializers.GlorotNormal,\n",
    "              bias_initializer=initializers.Zeros())(input_encoder)\n",
    "\n",
    "x_P1 = MaxPooling2D(pool_size = (3,1), strides = (2,1), padding='same', name = 'x_P1')(x_C1)\n",
    "\n",
    "x_C2 = Conv2D(filters = 8, kernel_size = (3,3), padding=\"same\", \n",
    "              activation=act_fun, name = 'x_C2',\n",
    "              kernel_initializer=initializers.GlorotNormal,\n",
    "              bias_initializer=initializers.Zeros())(x_P1)\n",
    "\n",
    "x_P2 = MaxPooling2D(pool_size = (3,1), strides = (2,1), padding='same', name = 'x_P2')(x_C2)\n",
    "\n",
    "x_C3 = Conv2D(filters = 4, kernel_size = (3,3), padding=\"same\",\n",
    "              activation=act_fun, name = 'x_C3',\n",
    "              kernel_initializer=initializers.GlorotNormal,\n",
    "              bias_initializer=initializers.Zeros())(x_P2)\n",
    "\n",
    "\n",
    "# Flatten layer\n",
    "x_F = Flatten(name = 'x_F')(x_C3)\n",
    "\n",
    "\n",
    "# Dense layers\n",
    "x_D1 = Dense(512, activation=act_fun, name = 'x_D1',\n",
    "                  kernel_initializer=initializers.GlorotNormal,\n",
    "                  bias_initializer=initializers.Zeros())(x_F)\n",
    "x_D2 = Dense(128, activation=act_fun, name = 'x_D2',\n",
    "                  kernel_initializer=initializers.GlorotNormal,\n",
    "                  bias_initializer=initializers.Zeros())(x_D1)\n",
    "x_D3 = Dense(32, activation=act_fun, name = 'x_D3',\n",
    "                  kernel_initializer=initializers.GlorotNormal,\n",
    "                  bias_initializer=initializers.Zeros())(x_D2)\n",
    "x_D4 = Dense(8, activation=act_fun, name = 'x_D4',\n",
    "                 kernel_initializer=initializers.GlorotNormal,\n",
    "                 bias_initializer=initializers.Zeros())(x_D3)\n",
    "\n",
    "\n",
    "# Latent feature layer\n",
    "# Mean\n",
    "encoder_mu = Dense(latent_dim, name=\"Encoder_Mu\")(x_D4)\n",
    "# Log-variance\n",
    "encoder_log_variance = Dense(latent_dim, name=\"Encoder_LogVariance\")(x_D4)\n",
    "\n",
    "\n",
    "# Sampling\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = tensorflow.keras.backend.random_normal(shape=tensorflow.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + tensorflow.keras.backend.exp(log_variance)*epsilon\n",
    "    return random_sample\n",
    "\n",
    "\n",
    "# Encoder\n",
    "output_encoder = Lambda(sampling, name=\"Encoder_Output\")([encoder_mu, encoder_log_variance])\n",
    "encoder = Model([input_encoder], [output_encoder], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the encoder information\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the encoder architecture\n",
    "plot_model(encoder, figure_dir + \"/Encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## Decoder\n",
    "### Note: The number of filters, kernel size, strides, padding, and number of nodes in dense layers are symmetric to the ones for encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_decoder = Input(shape=(latent_dim), name = 'Decoder_Input')\n",
    "\n",
    "\n",
    "# Denses layer\n",
    "y_D1 = Dense(8, activation=act_fun, name = 'y_D1',\n",
    "                kernel_initializer=initializers.GlorotNormal,\n",
    "                bias_initializer=initializers.Zeros())(input_decoder)\n",
    "y_D2 = Dense(32, activation=act_fun, name = 'y_D2',\n",
    "                 kernel_initializer=initializers.GlorotNormal,\n",
    "                 bias_initializer=initializers.Zeros())(y_D1)\n",
    "y_D3 = Dense(128, activation=act_fun, name = 'y_D3',\n",
    "                  kernel_initializer=initializers.GlorotNormal,\n",
    "                  bias_initializer=initializers.Zeros())(y_D2)\n",
    "y_D4 = Dense(512, activation=act_fun, name = 'y_D4',\n",
    "                  kernel_initializer=initializers.GlorotNormal,\n",
    "                  bias_initializer=initializers.Zeros())(y_D3)\n",
    "y_D5 = Dense(x_F.shape[1], activation=act_fun, name = 'y_D5',\n",
    "                           kernel_initializer=initializers.GlorotNormal,\n",
    "                           bias_initializer=initializers.Zeros())(y_D4)\n",
    "\n",
    "\n",
    "# Inverse flatten layer\n",
    "y_F = Reshape([x_C3.shape[1], x_C3.shape[2],x_C3.shape[3]], name = 'y_F')(y_D5)\n",
    "\n",
    "\n",
    "# Deconvolutional layers\n",
    "y_C1 = Conv2DTranspose(filters = 8, strides = (1,1), kernel_size = (3,3), padding=\"same\", \n",
    "                       activation=act_fun, name = 'y_C1',\n",
    "                       kernel_initializer=initializers.GlorotNormal,\n",
    "                       bias_initializer=initializers.Zeros())(y_F)                                                     \n",
    "\n",
    "y_C2 = Conv2DTranspose(filters = 8, strides = (2,1), kernel_size = (3,3), padding=\"same\", \n",
    "                       activation=act_fun, name = 'y_C2',\n",
    "                       kernel_initializer=initializers.GlorotNormal,\n",
    "                       bias_initializer=initializers.Zeros())(y_C1)                                                     \n",
    "\n",
    "y_C3 = Conv2DTranspose(filters = 16, strides = (1,1), kernel_size = (3,3), padding=\"same\", \n",
    "                       activation=act_fun, name = 'y_C3',\n",
    "                       kernel_initializer=initializers.GlorotNormal,\n",
    "                       bias_initializer=initializers.Zeros())(y_C2)  \n",
    "\n",
    "y_C4 = Conv2DTranspose(filters = 16, strides = (2,1), kernel_size = (3,3), padding=\"same\", \n",
    "                       activation=act_fun, name = 'y_C4',\n",
    "                       kernel_initializer=initializers.GlorotNormal,\n",
    "                       bias_initializer=initializers.Zeros())(y_C3)   \n",
    "\n",
    "y_C5 = Conv2DTranspose(filters = 1, kernel_size = (3,3), padding=\"same\", \n",
    "                       activation=act_fun, name = 'y_C5',\n",
    "                       kernel_initializer=initializers.GlorotNormal,\n",
    "                       bias_initializer=initializers.Zeros())(y_C4)    \n",
    "\n",
    "output_decoder = Conv2DTranspose(filters = 1, kernel_size = (3,3), padding=\"same\", \n",
    "                                 activation='linear', name = 'Decorder_Output',\n",
    "                                 kernel_initializer=initializers.GlorotNormal,\n",
    "                                 bias_initializer=initializers.Zeros())(y_C5) \n",
    "\n",
    "\n",
    "# Decoder\n",
    "decoder = Model([input_decoder], [output_decoder], name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the decoder information\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decoder architecture\n",
    "plot_model(decoder, figure_dir + \"/Decoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "input_auto = input_encoder\n",
    "\n",
    "# Output\n",
    "output_auto = decoder(encoder(input_encoder))\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model([input_auto], [output_auto], name='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the autoencoder information\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the autoencoder architecture\n",
    "plot_model(autoencoder, figure_dir + \"/Autoencoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "# Mean squared error\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "loss_mse = mse(input_auto, output_auto)\n",
    "\n",
    "# KL-divergence\n",
    "loss_kl = -0.5*tf.keras.backend.sum(1.0 + encoder_log_variance - tf.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
    "   \n",
    "# Add loss to autoencoder \n",
    "loss = loss_mse + loss_kl*0.001\n",
    "autoencoder.add_loss(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "autoencoder.compile(optimizer=optimizers.Adam(learning_rate=Learning_Rate))\n",
    "\n",
    "# Initial learning rate step decay \n",
    "def lr_step_decay(epoch, lr):\n",
    "    if epoch < NUM_EPOCH_DROP1:\n",
    "        return Learning_Rate * math.pow(Drop_Rate1, math.floor(epoch/Drop_Epoch))\n",
    "    if ((epoch >= NUM_EPOCH_DROP1) and (epoch < NUM_EPOCH_DROP2)):\n",
    "        return Learning_Rate * math.pow(Drop_Rate1, math.floor(NUM_EPOCH_DROP1/Drop_Epoch)) * math.pow(Drop_Rate2, math.floor((epoch-NUM_EPOCH_DROP1)/Drop_Epoch))\n",
    "    if ((epoch >= NUM_EPOCH_DROP2) and (epoch < NUM_EPOCH_DROP3)):\n",
    "        return Learning_Rate * math.pow(Drop_Rate1, math.floor(NUM_EPOCH_DROP1/Drop_Epoch)) * math.pow(Drop_Rate2, math.floor((NUM_EPOCH_DROP2-NUM_EPOCH_DROP1)/Drop_Epoch)) * math.pow(Drop_Rate3, math.floor((epoch-NUM_EPOCH_DROP2)/Drop_Epoch))\n",
    "    if epoch >= NUM_EPOCH_DROP3:\n",
    "        return Learning_Rate * math.pow(Drop_Rate1, math.floor(NUM_EPOCH_DROP1/Drop_Epoch)) * math.pow(Drop_Rate2, math.floor((NUM_EPOCH_DROP2-NUM_EPOCH_DROP1)/Drop_Epoch)) * math.pow(Drop_Rate3, math.floor((NUM_EPOCH_DROP3-NUM_EPOCH_DROP2)/Drop_Epoch)) * math.pow(Drop_Rate4, math.floor((epoch-NUM_EPOCH_DROP3)/Drop_Epoch))\n",
    "              \n",
    "LR_Scheduler = tf.keras.callbacks.LearningRateScheduler(lr_step_decay, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint path and direction\n",
    "checkpoint_path = model_dir + \"/Checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to save the model's weights at the best epoch\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 verbose = 1, \n",
    "                                                 monitor='loss',\n",
    "                                                 mode='min',\n",
    "                                                 save_weights_only = True,\n",
    "                                                 save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop when the loss reaches a user-defined value\n",
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') <= Loss_Stop):\n",
    "            print(\"\\n\\n\\nReached %s loss value, so stopping training!\\n\\n\\n\"  %(str(Loss_Stop)))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "trainingStopCallback = haltCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output data\n",
    "Input_set = T\n",
    "Output_set = T\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = T.shape[0]\n",
    "\n",
    "# Training\n",
    "start = time.time()\n",
    "history = autoencoder.fit(Input_set, Output_set,\n",
    "                          epochs = NUM_EPOCH,\n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          callbacks = [cp_callback, trainingStopCallback, LR_Scheduler],\n",
    "                          verbose = 0)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and save the running time\n",
    "print(\"The running time:\", round((end-start)/60,1), \"mins\")\n",
    "print('')\n",
    "\n",
    "Time = np.asarray(round((end-start)/60,1))\n",
    "Time = Time.reshape(1,-1)\n",
    "np.savetxt(data_dir + \"/Running_Time.txt\", Time);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best checkpoint, which is associated with the smallest loss value\n",
    "loss_min_index = history.history['loss']. index(min(history.history['loss']))\n",
    "ckpt_best = loss_min_index+1\n",
    "print('Number of epochs at the minimum loss = ', ckpt_best)\n",
    "print('')\n",
    "\n",
    "Min_Loss_Epoch = open(data_dir + '/Min_Loss_Epoch.dat', 'w')\n",
    "Min_Loss_Epoch.write(str(ckpt_best))\n",
    "Min_Loss_Epoch.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint ID\n",
    "Checkpoint_ID = os.path.join(model_dir, \"Checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "autoencoder_best = autoencoder\n",
    "autoencoder_best.load_weights(Checkpoint_ID)\n",
    "\n",
    "# Autoencoder output\n",
    "auto_output_raw = autoencoder_best.predict(T,verbose = 0);\n",
    "auto_output = auto_output_raw.reshape(T.shape[0],T.shape[1]*T.shape[2])\n",
    "np.savetxt(data_dir + '/Autoencoder_Output.dat', auto_output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_best = encoder\n",
    "\n",
    "# Load weights from autoencoder_best\n",
    "encoder_len = len(encoder_best.weights)\n",
    "encoder_best.set_weights(autoencoder_best.weights[0:encoder_len])\n",
    "\n",
    "# mu\n",
    "layer_mu = 'Encoder_Mu'\n",
    "mu_best = Model(inputs = autoencoder_best.input, outputs = autoencoder_best.get_layer(layer_mu).output);\n",
    "mu = mu_best.predict(T,verbose = 0);\n",
    "np.savetxt(data_dir + '/Encode_Mu.dat', mu);\n",
    "\n",
    "# log variance\n",
    "layer_logvariance = 'Encoder_LogVariance'\n",
    "logvariance_best = Model(inputs = autoencoder_best.input, outputs = autoencoder_best.get_layer(layer_logvariance).output);\n",
    "logvariance = logvariance_best.predict(T,verbose = 0);\n",
    "np.savetxt(data_dir + '/Encode_LogVariance.dat', logvariance);\n",
    "\n",
    "# Encoder output\n",
    "layer_encoder_output = 'encoder'\n",
    "encoder_output_best = Model(inputs = autoencoder_best.input, outputs = autoencoder_best.get_layer(layer_encoder_output).output);\n",
    "encoder_output = encoder_output_best.predict(T,verbose = 0);\n",
    "np.savetxt(data_dir + '/Encode_Output.dat', encoder_output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_best = decoder\n",
    "\n",
    "# Load weights from autoencoder_best\n",
    "decoder_len = len(decoder_best.weights)\n",
    "decoder_best.set_weights(autoencoder_best.weights[encoder_len:encoder_len+decoder_len])\n",
    "\n",
    "# Decoder output\n",
    "decoder_output_raw = decoder_best.predict(encoder_output,verbose = 0);\n",
    "decoder_output = decoder_output_raw.reshape(T.shape[0],T.shape[1]*T.shape[2])\n",
    "np.savetxt(data_dir + '/Decoder_Output.dat', decoder_output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "np.savetxt(data_dir + '/Loss.dat', history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
